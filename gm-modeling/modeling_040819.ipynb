{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSS General Membership Meeting #7\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced Analysis & Drawing Conclusions\n",
    "#### Monday, April 8, 2019\n",
    "\n",
    "acknowledgement: Data100 course material\n",
    "\n",
    "---\n",
    "\n",
    "Today we will be looking in to ways to build models for predicting outcomes, and ways to understand how good your model is.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1 | Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our data. \n",
    "\n",
    "Run the following cell to load the data. We will use 2 separate dataframes in `boston_data`:\n",
    "    - `data` : the variables in matrix form (X)\n",
    "    - `target` : the known outcomes, in vector form (Y)\n",
    "\n",
    "Here are the features/variables we will be working with in this dataset in `data`:\n",
    "\n",
    "    1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per 10,000 USD\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of black \n",
    "                 residents by town\n",
    "    13. LSTAT    % lower status of the population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_data = load_boston()\n",
    "boston = pd.DataFrame(boston_data['data'], columns=boston_data['feature_names'])\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use se the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out 10% of the data for test. Call the resulting splits `X_train`, `X_test`, `Y_train`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(47)\n",
    "\n",
    "X = boston\n",
    "Y = pd.Series(boston_data['target'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fit a linear model to describe the relationship between the housing price and all available variables. We've imported `sklearn.linear_model` as `lm`. Fill in the cells below to fit a linear regression model and create a scatter plot for our predictions vs. the true prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_model = lm.LinearRegression()\n",
    "\n",
    "# Fit your linear model\n",
    "...\n",
    "\n",
    "# Fit your model on the training set\n",
    "Y_fitted = ...\n",
    "\n",
    "# Predict housing prices on the test set\n",
    "Y_pred = ...\n",
    "\n",
    "# Plot predicted vs true prices\n",
    "sns.scatterplot(Y_test, Y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Prices\")\n",
    "plt.ylabel(\"Predicted Prices\")\n",
    "plt.title(\"Actual Prices vs Predicted Prices\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our model is not perfect. If it were perfect, we would see the identity line (i.e. a line of slope 1). \n",
    "\n",
    "To see how we are doing, compute the root mean squared error (RMSE) of the predicted responses: \n",
    "\n",
    "$$\n",
    "\\textbf{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n \\left( y_i - \\hat{y}_i \\right)^2 }\n",
    "$$\n",
    "\n",
    "Fill out the function below and compute the RMSE for our predictions on both the training data `X_train` and the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual_y, predicted_y):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predicted_y: an array of the prediction from the model\n",
    "        actual_y: an array of the groudtruth label\n",
    "        \n",
    "    Returns:\n",
    "        The root mean square error between the prediction and the groudtruth\n",
    "    \"\"\"\n",
    "    return ...\n",
    "\n",
    "train_error = ...\n",
    "test_error = ...\n",
    "\n",
    "print(\"Training RMSE:\", train_error)\n",
    "print(\"Test RMSE:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2 | Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be working on the breast cancer dataset. This dataset can be easily loaded using the `sklearn.datasets.load_breast_cancer()` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_data = load_breast_cancer()\n",
    "cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to fit a simple model with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = cancer[[\"mean radius\"]]\n",
    "y = (cancer_data.target == 0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit our model using `sklearn.linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lm.LogisticRegression(fit_intercept=True, solver='lbfgs')\n",
    "\n",
    "...\n",
    "\n",
    "# Fit your model on the training set\n",
    "y_fitted = ...\n",
    "\n",
    "# Predict housing prices on the test set\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the training and testing accuracy for both of our training and test sets. Remember that accuracy is defined as the accurate labels (TP, TN) over the total amount of of items labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = ...\n",
    "test_accuracy = ...\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we can a get very high test accuracy. Then how about precision and recall?  \n",
    "- Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances.  \n",
    "- Recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "\n",
    "Precision is the ability of the classifier not to label as positive a sample that is negative while recall is the ability of the classifier to find all the positive samples.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_positives}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_negatives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a confusion matrix to help us calcuate these rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, lr.predict(x_test))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "class_names = ['False', 'True']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = ...\n",
    "recall = ...\n",
    "\n",
    "print(f'precision = {precision:.4f}')\n",
    "print(f'recall = {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 | Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are returning to our Boston dataset, and try building a simpler linear model with fewer features. While this may increase our training error, it may also decrease our test error and help prevent overfitting to the training set.\n",
    "\n",
    "We'll use $k$-fold cross-validation to select the best subset of features for our model.\n",
    "\n",
    "`Scikit-learn` has built-in support for cross validation.  However, to better understand how cross validation works complete the following function which cross validates a given model.\n",
    "\n",
    "1. Use the [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function to get 4 splits on the training data. Note that `split` returns the indices of the data for that split.\n",
    "2. For each split, select out the rows and columns based on the split indices and features.\n",
    "3. Compute the RMSE on the validation split.\n",
    "4. Return the average error across all cross validation splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def compute_CV_error(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 4 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the MSE on that subset (the validation set)\n",
    "    You should be fitting 4 models total.\n",
    "    Return the average MSE of these 4 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation MSE for the 4 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=4)\n",
    "    validation_errors = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = ..., ...\n",
    "        split_Y_train, split_Y_valid = ..., ...\n",
    "\n",
    "        # Fit the model on the training split\n",
    "        model.fit(..., ...)\n",
    "\n",
    "        # Compute the RMSE on the validation split\n",
    "        error = ...\n",
    "        \n",
    "        validation_errors.append(error)\n",
    "        \n",
    "    return np.mean(validation_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined four different feature sets, each containing three features (stored in `feature_sets` below). Use `compute_CV_error` to determine which feature set gets us the lowest average validation error. Then, fill in the variables `best_err_idx`, `best_err`, and `best_feature_set` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [\n",
    "    ['TAX', 'INDUS', 'CRIM'], \n",
    "    ['RM', 'LSTAT', 'PTRATIO'], \n",
    "    ['RM', 'B', 'NOX'], \n",
    "    ['TAX', 'LSTAT', 'DIS']\n",
    "]\n",
    "\n",
    "errors = []\n",
    "for feat in feature_sets:\n",
    "    print(\"Trying features:\", feat)\n",
    "    model = lm.LinearRegression()\n",
    "    # compute the cross validation error\n",
    "    error = compute_CV_error(model, X_train[feat], Y_train)\n",
    "    \n",
    "    print(\"\\tRMSE:\", error)\n",
    "    errors.append(error)\n",
    "\n",
    "best_err_idx = ...\n",
    "best_err = ...\n",
    "best_feature_set = ...\n",
    "\n",
    "for i in range(4):\n",
    "    print('{}, error: {}'.format(feature_sets[i], errors[i]))\n",
    "\n",
    "best_feature_set, best_err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
